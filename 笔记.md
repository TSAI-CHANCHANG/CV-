CNN 卷积神经网络 Convolutional Neural Network

Image Style Transfer Using Convolutional Neural Networks

#### 1. Introduction

简介：可以說，以前方法的一個主要限制因素是缺乏明確表示語義信息的圖像表示，因此允許將圖像內容與樣式分開。该论文采用了一种由为图像识别而优化的CNN网络派生来的图像表示，该表示方法可让高级图像信息显而易见。

图像风格转换可被认为是纹理转换。该文认为图像风格转换函数应该能够从目标图片中提取图像语义内容（例如对象+背景），然后让纹理转换器用源图像的风格渲染目标图像语义内容。

因此，基本的先决条件是找到独立地模拟语义图像内容的变化和其呈现方式的图像表示。

Content Reconstructions 低层网络的内容重构效果不错，高层网络内容重构高等级内容保留，像素级别的细节丢失。

Style Reconstructions 创建了符合给定图像风格的可增长大小的图片，但是丢失了全局布局。

这个技术之前只用于自然图像的部分特定子集（比如在不同光照下的人脸）或是不同的字体风格的字母。

CNN创造的计算机视觉系统可以学习从自然图像中提取高级别语义信息。

**该论文主要内容：1. 如何通过高性能卷积神经网络学习的通用特征表示来独立处理和操纵自然图像的内容和风格。**

**2. 介绍一种新图像风格转换算法**

#### 2. Deep image representations

使用的是19层VGG网络，拥有16层卷积层与5层池化层。没有全连接层。用伸缩权重来正则化网络（可以在不改变其输出的情况下对VGG网络进行这种重新缩放，因为它仅包含整流线性激活函数并且不对特征映射进行归一化或池化）。对于图像生成他们发现将maximum pooling换成average pooling效果好很多。

##### 2.1. Content representation

一层拥有Nl个不同的过滤器的网络拥有Nl个特征map，每个特征map大小Ml（=长x宽）。第l层的response可被存放于一个矩阵中。

F上l下ij  是第l层的第i个filter在位置j的activation（位置j指的是该filter对应的map中的位置，map序列化）

由此定义了平方损失

CNN被用于训练目标识别时，会建立一种图像表示机制。随着过程推荐，对象信息会逐渐清晰。对于图像的真实内容会逐渐敏感。高层网络把握了输入图片中高层次内容与排布，但是对于像素级元素的重建却不是约束得那么精确。底层网络重建只是还原了原图片对应点的内容。

**高层次的feature response称为content representation**

##### 2.2. Style representation

为表示input image的style，作者使用一个特征空间（feature space）以捕捉纹理信息。同点不同filter的activation的内积被称为 Gram矩阵。

Gram函数：Gij 先求第i个和第j个filter在同个点的activation的内积，然后求出map上所有点的每个点内积，最后再求和

通过包括多层特征的相关性，我们获得输入图像的静态多尺度表示，捕获其纹理信息但不捕获全局排列。derivative 导数

##### 2.3. Style transfer

现要生成一个内容为照片p，风格为艺术品a的图片，生成的图片为x。

需要同时减小：1. 白噪音的特征表示矩阵和单层照片的内容矩阵间的距离；2. 白噪音的特征表示矩阵和数层绘画风格表示矩阵间的距离。

此处下降法采用L-BFGS法最优。为了能够在可比较的比例上提取图像信息，会实现将所有的style image重新调整大小。没有使用图像先验来规范我们的综合结果。（可能具有争议性）来自低层的纹理特征可以扮演style image的先验图像的角色。在图片生成中的一些不同与不同的神经网络结构、优化方法有关。

方法：

1. 先把风格来源图片a与照片p分别塞进CNN。
2. 所有层的style representation Al都会被计算并保存。（也就是所有用于比较的局部特征与当前图像的卷积，所有这些卷积之间的内积，这些内积的和）
3. 一层的content representation会被保存。
4. 将一个随机生成的白噪音图片传给CNN，他的style feature和context feature也会被计算出来。
5. 计算白噪音和每层style图片之间的style loss，然后分配权重加权计算总style的loss  Lstyle
6. 白噪音图片对应层的content representation与照片对应层的content representation之间的loss计算  Lcontext
7. 计算总的损失Ltotal
8. 后向传播，逐步让Ltotal减到最小，获得最后的生成图片。

Ltotal为Lstyle和Lcontext间的加权之和，调整权重即可决定让生成的图片更加注重照片还是更注重风格。

##### 几大问题

算力不足 如果style图片也是照片就很容易受到噪音干扰 如何定义style（因而无法确定能否完全把内容和风格分开）

为何通过卷积层以后，长宽减少了，厚度却增加了：

![](.\笔记1.webp)

如图所示，卷积实际上就是将局部的一小部分特征与待比较对象的某一部分进行比较。本例中9x9的图在卷积后就只剩下7x7。但是局部特征的数量上涨后就会导致厚度增加。

几大知名的CNN模型：

1. AlexNet

   说明博客：<https://blog.csdn.net/daydayup_668819/article/details/79744095>

   特点：使用了线性的激活函数ReLU f(u)=max(0,u)；

   ​	   加入防止过拟合的办法：

   ​	   	Dropout 队某一层的神经元，通过定义的概率将神经元置为0，可看作一种模型组合，每次生成的网络结构都不一样，通过组合		   多个模型的方式有效减少过拟合。

   ​		   数据扩充 变换已有的训练数据生成新的数据（水平反转图像，颜色变化等）

   ​	   重复池化 池化移动的步长小于池化窗口的大小。

   ​	   局部归一化（Local Response Normalization, LRN）

   

   AlexNet有五层卷积层：

   ​	   第一第二层：卷积->ReLU->池化->归一化

   ​	   第三第四层：卷积->ReLU

   ​	   第五层：卷积->ReLU->池化

   三层全连接层：

   ​	   第六第七层：全连接->ReLU->Dropout

   ​	   第八层：全连接

2. GoogLe

   说明博客：<https://my.oschina.net/u/876354/blog/1637819>

   Inception V1: 设计一个稀疏网络结构，但是能够产生稠密的数据，既能增加神经网络表现，又能保证计算资源的使用效率。

   1x1的卷积核用途为减少维度。

   为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度（辅助分类器）。辅助分类器是将中间某一层的输出用作分类，并按一个较小的权重（0.3）加到最终分类结果中，这样相当于做了模型融合，同时给网络增加了反向传播的梯度信号，也提供了额外的正则化，对于整个网络的训练很有裨益。而在实际测试的时候，这两个额外的softmax会被去掉。

3. ResNet

   深度残差网络（Deep residual network, ResNet）

4. s

   

   ​	

